{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:00:05.906836Z","iopub.execute_input":"2025-09-06T10:00:05.907124Z","iopub.status.idle":"2025-09-06T10:00:05.911910Z","shell.execute_reply.started":"2025-09-06T10:00:05.907103Z","shell.execute_reply":"2025-09-06T10:00:05.911288Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import triton \nimport torch \nimport triton.language as tl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:00:06.743387Z","iopub.execute_input":"2025-09-06T10:00:06.743626Z","iopub.status.idle":"2025-09-06T10:00:06.747304Z","shell.execute_reply.started":"2025-09-06T10:00:06.743608Z","shell.execute_reply":"2025-09-06T10:00:06.746535Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:00:07.587318Z","iopub.execute_input":"2025-09-06T10:00:07.587579Z","iopub.status.idle":"2025-09-06T10:00:07.591430Z","shell.execute_reply.started":"2025-09-06T10:00:07.587557Z","shell.execute_reply":"2025-09-06T10:00:07.590690Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"@triton.jit \ndef __attn_fwd_inner(Q,O,L,M,K_ptr,V_ptr,K_T_offsets,V_offsets,block_index_QO,softmax_scale,stride_K_SEQ_LEN,\n                    stride_V_SEQ_LEN,BLOCK_SIZE_QO:tl.constexpr,BLOCK_SIZE_KV:tl.constexpr,\n                    DIAGONAL:tl.constexpr,offset_QO_SEQ_LEN,offset_KV_SEQ_LEN,\n                    SEQ_LEN:tl.constexpr,HEAD_DIM:tl.constexpr):\n    if DIAGONAL:\n        lo = block_index_QO* BLOCK_SIZE_QO\n        hi = (block_index_QO+1)* BLOCK_SIZE_QO\n\n        lo = tl.multiple_of(lo,BLOCK_SIZE_QO)\n    else:\n        lo = 0 \n        hi = block_index_QO* BLOCK_SIZE_QO\n    #move offsets \n    K_T_offsets+= lo*stride_K_SEQ_LEN\n    V_offsets+= lo* stride_V_SEQ_LEN\n    offset_KV_SEQ_LEN+= lo \n\n    for start_kv in range(lo,hi,BLOCK_SIZE_KV):\n        start_kv = tl.multiple_of(start_kv,BLOCK_SIZE_KV)\n\n        mask_KV_SEQ_LEN = offset_KV_SEQ_LEN < SEQ_LEN\n\n        K_DATA_T  = tl.load(K_ptr+K_T_offsets,mask = mask_KV_SEQ_LEN[:,None],other=0.0)\n        K_DATA_T = tl.trans(K_DATA_T)\n        S = tl.dot(Q,K_DATA_T) * softmax_scale\n\n        if DIAGONAL:\n            causal_mask  = offset_QO_SEQ_LEN[:,None] >= offset_KV_SEQ_LEN[None,:]\n            S = tl.where(causal_mask,S,float('-inf'))\n        M_new = tl.maximum(M,tl.max(S,axis=1))\n        S -= M_new[:,None]\n        P = tl.exp2(S) #BLOCK_SIZE_OQ * BLOCK_SIZE_KV\n        L_new = tl.sum(P,axis=1)\n\n        alpha = tl.exp2(M-M_new) # BLOCK_SIZE_OQ\n        L = L *alpha + L_new\n        V = tl.load(V_ptr+V_offsets,mask =  mask_KV_SEQ_LEN[:,None],other=0.0)\n        O = O* alpha[:,None] # ALPHA[:,None] = shape of alpha is [BLOCK_SIZE_OQ,1]\n        #o shape is BLOCK_SIZE_OQ * HEAD_DIM\n        O = tl.dot(P,V,acc=O)\n        M = M_new\n        K_T_offsets += BLOCK_SIZE_KV * stride_K_SEQ_LEN\n        V_offsets += BLOCK_SIZE_KV * stride_V_SEQ_LEN\n        offset_KV_SEQ_LEN += BLOCK_SIZE_KV\n    return O,L,M\n        \n        \n\n@triton.autotune(\n    configs=[\n        triton.Config({'BLOCK_SIZE_QO': 16, 'BLOCK_SIZE_KV': 16}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 16, 'BLOCK_SIZE_KV': 32}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 16, 'BLOCK_SIZE_KV': 64}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 32, 'BLOCK_SIZE_KV': 16}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 32, 'BLOCK_SIZE_KV': 32}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 32, 'BLOCK_SIZE_KV': 64}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 64, 'BLOCK_SIZE_KV': 16}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 64, 'BLOCK_SIZE_KV': 32}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 64, 'BLOCK_SIZE_KV': 64}, num_stages=4, num_warps=4),\n        triton.Config({'BLOCK_SIZE_QO': 128, 'BLOCK_SIZE_KV': 32}, num_stages=4, num_warps=8),\n        triton.Config({'BLOCK_SIZE_QO': 128, 'BLOCK_SIZE_KV': 64}, num_stages=4, num_warps=8),\n    ],\n    key=['SEQ_LEN', 'HEAD_DIM'],\n)\n@triton.jit\ndef attn_fwd(Q_PTR,K_PTR,V_PTR,O_PTR,LSE_PTR,softmax_scale,\n            stride_Q_BATCH,stride_Q_N_HEADS,stride_Q_SEQ_LEN,stride_Q_HEAD_DIM,\n            stride_K_BATCH,stride_K_N_HEADS,stride_K_SEQ_LEN,stride_K_HEAD_DIM,\n            stride_V_BATCH,stride_V_N_HEADS,stride_V_SEQ_LEN,stride_V_HEAD_DIM,\n            stride_O_BATCH,stride_O_N_HEADS,stride_O_SEQ_LEN,stride_O_HEAD_DIM,\n            stride_LSE_BATCH,stride_LSE_N_HEADS,stride_LSE_SEQ_LEN,\n            BATCH_SIZE,N_HEADS:tl.constexpr,SEQ_LEN:tl.constexpr,HEAD_DIM:tl.constexpr,\n            BLOCK_SIZE_QO:tl.constexpr,BLOCK_SIZE_KV:tl.constexpr \n            ):\n    rln2: tl.constexpr = 1.4426950408889634\n    softmax_scale *= rln2\n    tl.static_assert(BLOCK_SIZE_KV<=HEAD_DIM)\n    block_index_QO = tl.program_id(0)\n    block_head_id = tl.program_id(1)\n    batch_index  = block_head_id // N_HEADS\n    head_index = block_head_id % N_HEADS\n\n    ##ptr moving to correct batch and head \n    Q_PTR+= batch_index * stride_Q_BATCH + head_index*stride_Q_N_HEADS\n    K_PTR+= batch_index * stride_K_BATCH + head_index*stride_K_N_HEADS\n    V_PTR+= batch_index * stride_V_BATCH + head_index*stride_V_N_HEADS\n    O_PTR+= batch_index * stride_O_BATCH + head_index*stride_O_N_HEADS\n\n    offset_QO_SEQ_LEN = block_index_QO* BLOCK_SIZE_QO + tl.arange(0,BLOCK_SIZE_QO)\n    offset_KV_SEQ_LEN  = tl.arange(0,BLOCK_SIZE_KV)\n    offset_HEAD_DIM = tl.arange(0,HEAD_DIM)\n\n    Q_offsets  = offset_QO_SEQ_LEN[:,None] * stride_Q_SEQ_LEN + offset_HEAD_DIM[None,:]* stride_Q_HEAD_DIM\n    K_T_offsets  =  offset_KV_SEQ_LEN[:,None]* stride_K_SEQ_LEN + offset_HEAD_DIM[None,:]* stride_K_HEAD_DIM #not yet transposed we tranpose while loading \n    V_offsets  = offset_KV_SEQ_LEN[:,None]* stride_V_SEQ_LEN + offset_HEAD_DIM[None,:]* stride_V_HEAD_DIM\n    mask_OQ_SEQ_LEN = offset_QO_SEQ_LEN < SEQ_LEN\n\n    Q_data = tl.load(Q_PTR+Q_offsets,mask = mask_OQ_SEQ_LEN[:,None],other= 0.0)\n\n    M = tl.full(shape=[BLOCK_SIZE_QO],value = float(\"-inf\"),dtype=tl.float32)\n    L = tl.full(shape=[BLOCK_SIZE_QO],value = float(1),dtype=tl.float32)\n    O = tl.zeros([BLOCK_SIZE_QO,HEAD_DIM],dtype=tl.float32)\n\n    O,L,M = __attn_fwd_inner(\n        Q_data,O,L,M,K_PTR,V_PTR,K_T_offsets,V_offsets,block_index_QO,softmax_scale,stride_K_SEQ_LEN,stride_V_SEQ_LEN,\n        BLOCK_SIZE_QO,BLOCK_SIZE_KV,False,offset_QO_SEQ_LEN,offset_KV_SEQ_LEN,SEQ_LEN,HEAD_DIM\n        \n    )\n\n    O,L,M = __attn_fwd_inner(\n        Q_data,O,L,M,K_PTR,V_PTR,K_T_offsets,V_offsets,block_index_QO,softmax_scale,stride_K_SEQ_LEN,stride_V_SEQ_LEN,\n        BLOCK_SIZE_QO,BLOCK_SIZE_KV,True,offset_QO_SEQ_LEN,offset_KV_SEQ_LEN,SEQ_LEN,HEAD_DIM\n        \n    )\n\n    O = O / L[:,None] #BLOCK_SIZE_OQ,HEAD_DIM / BLOCK_SIZE_OQ,1 = BLOCK_SIZE_OQ,HEAD_DIM\n    LSE = M+ tl.math.log2(L)\n    LSE_offsets = batch_index*stride_LSE_BATCH + offset_QO_SEQ_LEN\n    LSE_mask = block_index_QO * BLOCK_SIZE_QO + tl.arange(0, BLOCK_SIZE_QO) < SEQ_LEN\n    tl.store(LSE_PTR + LSE_offsets, LSE, mask=LSE_mask) # shape (BLOCK_SIZE_QO)\n\n    O_offsets = offset_QO_SEQ_LEN[:,None] * stride_O_SEQ_LEN + offset_HEAD_DIM[None,:]* stride_O_HEAD_DIM\n    tl.store(O_PTR+O_offsets,O,mask=mask_OQ_SEQ_LEN[:,None])\n\n\n\n\nclass FlashAttn(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx,q,k,v,scale):\n        assert q.shape[-1]==k.shape[-1]==v.shape[-1]\n        assert q.shape[-1]<=128 #only support max_head dim of size 128\n        assert q.device==k.device==v.device\n        assert q.dtype == k.dtype == v.dtype == torch.float32\n        BS,N_HEADS,SEQ_LEN,HEAD_DIM = q.shape\n        O = torch.empty_like(q) \n        LSE =  torch.empty((BS,N_HEADS,SEQ_LEN),device=q.device,dtype=torch.float32)\n\n        grid = lambda args : (\n            triton.cdiv(SEQ_LEN,args['BLOCK_SIZE_QO']),\n            BS*N_HEADS\n        )  #we dont do it in other way because sm's work on cache and its better to have them stack same kv blocks together \n\n        #0,0,1,0,  \n        attn_fwd[grid](\n            q,k,v,O,LSE,scale,\n            q.stride(0),q.stride(1),q.stride(2),q.stride(3),\n            k.stride(0),k.stride(1),k.stride(2),k.stride(3),\n            v.stride(0),v.stride(1),v.stride(2),v.stride(3),\n            O.stride(0),O.stride(1),O.stride(2),O.stride(3),\n            LSE.stride(0),LSE.stride(1),LSE.stride(2),\n            BS,N_HEADS,SEQ_LEN,HEAD_DIM,\n            \n        )\n        ctx.save_for_backward(q,k,v,O,LSE)\n        ctx.grid = grid\n        ctx.BS = BS\n        ctx.N_HEADS = N_HEADS\n        ctx.SEQ_LEN = SEQ_LEN \n        ctx.HEAD_DIM = HEAD_DIM\n        ctx.scale = scale\n        return O\n        \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:26:40.390401Z","iopub.execute_input":"2025-09-06T10:26:40.390677Z","iopub.status.idle":"2025-09-06T10:26:40.426793Z","shell.execute_reply.started":"2025-09-06T10:26:40.390654Z","shell.execute_reply":"2025-09-06T10:26:40.426046Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"triton_attention = FlashAttn.apply\ndef test_flash_attn(BS,N_HEADS,SEQ_LEN,HEAD_DIM,device=DEVICE,atol=5e-3):\n    q = torch.randn(BS,N_HEADS,SEQ_LEN,HEAD_DIM,device=device,dtype=torch.float32)\n    k = torch.randn(BS,N_HEADS,SEQ_LEN,HEAD_DIM,device=device,dtype=torch.float32)\n    v = torch.randn(BS,N_HEADS,SEQ_LEN,HEAD_DIM,device=device,dtype=torch.float32)\n    scale = 1/(HEAD_DIM**0.5)\n    tri_out = triton_attention(q,k,v,scale)\n    ref_out = torch.nn.functional.scaled_dot_product_attention(q, k, v, is_causal=True)\n    triton.testing.assert_close(tri_out,ref_out,atol=atol,rtol=0)\n    return tri_out,ref_out\n    \n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:26:41.732909Z","iopub.execute_input":"2025-09-06T10:26:41.733645Z","iopub.status.idle":"2025-09-06T10:26:41.738684Z","shell.execute_reply.started":"2025-09-06T10:26:41.733623Z","shell.execute_reply":"2025-09-06T10:26:41.738072Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"test_flash_attn(1,1,128,32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-06T10:26:42.560831Z","iopub.execute_input":"2025-09-06T10:26:42.561297Z","iopub.status.idle":"2025-09-06T10:26:49.947809Z","shell.execute_reply.started":"2025-09-06T10:26:42.561273Z","shell.execute_reply":"2025-09-06T10:26:49.947070Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"(tensor([[[[ 1.7829e-01, -1.5816e-01,  1.2091e-01,  ...,  2.4630e+00,\n             7.9585e-01, -2.1501e-01],\n           [-1.9836e-01, -1.0919e-03,  2.2382e-01,  ...,  2.2296e+00,\n             1.3938e-01, -2.9992e-01],\n           [-2.1720e-01, -1.1830e-01, -1.6409e-02,  ...,  1.7270e+00,\n            -3.0924e-01,  2.0510e-01],\n           ...,\n           [-7.1058e-02,  2.1507e-01,  3.2266e-01,  ...,  5.2523e-02,\n             9.8962e-03,  1.8218e-01],\n           [ 6.1470e-02,  9.7897e-02,  2.0129e-01,  ...,  9.8208e-02,\n             1.2815e-02,  5.8018e-02],\n           [ 2.0506e-01,  7.9163e-02,  1.3703e-01,  ...,  7.2430e-02,\n             3.2650e-02, -1.7212e-01]]]], device='cuda:0'),\n tensor([[[[ 1.7829e-01, -1.5816e-01,  1.2091e-01,  ...,  2.4630e+00,\n             7.9585e-01, -2.1501e-01],\n           [-1.9836e-01, -1.0919e-03,  2.2382e-01,  ...,  2.2296e+00,\n             1.3938e-01, -2.9992e-01],\n           [-2.1720e-01, -1.1830e-01, -1.6409e-02,  ...,  1.7270e+00,\n            -3.0924e-01,  2.0510e-01],\n           ...,\n           [-7.1058e-02,  2.1507e-01,  3.2266e-01,  ...,  5.2523e-02,\n             9.8962e-03,  1.8218e-01],\n           [ 6.1470e-02,  9.7897e-02,  2.0129e-01,  ...,  9.8208e-02,\n             1.2815e-02,  5.8018e-02],\n           [ 2.0506e-01,  7.9163e-02,  1.3703e-01,  ...,  7.2430e-02,\n             3.2650e-02, -1.7212e-01]]]], device='cuda:0'))"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}